{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bounding Box",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMko8EEXsGi4WttyG4AidPo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohan-gopalam/bounding-box-for-mnist/blob/main/Bounding_Box.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from os import listdir\n",
        "import glob\n",
        "import numpy as np\n",
        "from scipy import misc\n",
        "import h5py\n",
        "\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "random.seed(101)\n",
        "def build_synth_data(data,labels,dataset_size):\n",
        "\n",
        "\n",
        "    #dimesions of the 224x224 main pic which a 28x(28*n) n digitimage will be inserted\n",
        "    synth_img_height = 224\n",
        "    synth_img_width = 224\n",
        "    \n",
        "    #creating new dataset\n",
        "    synth_data = []\n",
        "    \n",
        "    synth_labels = [] \n",
        "    \n",
        "    #creating a string of n images\n",
        "    for i in range(0,dataset_size):\n",
        "        \n",
        "        num_digits = random.randint(1,5)\n",
        "        \n",
        "        #getting a random index from the data\n",
        "        synth_indices = [random.randint(0,len(data)-1) for p in range(0,num_digits)]\n",
        "        \n",
        "        #using the indices above to chain together a string of n digit images from the data\n",
        "        new_small_image = np.hstack([data[index] for index in synth_indices])\n",
        "        \n",
        "        #where the n digit number will be inserted in the 400x400 main matrix\n",
        "        starting_left = random.randint(1,synth_img_width-(num_digits*28))\n",
        "        starting_bottom = random.randint(28,synth_img_height-1)\n",
        "        starting_right = starting_left + num_digits*28\n",
        "        starting_top = starting_bottom - 28 \n",
        "        small_img_width = num_digits*28\n",
        "\n",
        "        #creating a label\n",
        "        new_label =  [starting_left, starting_top, starting_right, starting_bottom]\n",
        "       \n",
        "\n",
        "        left_zeros = np.empty(shape = [28, starting_left])\n",
        "        right_zeros = np.empty(shape = [28, synth_img_width - starting_left - (28*num_digits)])\n",
        "        bottom_zeros = np.empty(shape = [synth_img_height-starting_bottom,synth_img_height])\n",
        "        top_zeros = np.empty(shape = [starting_top,synth_img_height])\n",
        "\n",
        "        #adding the n digit number matrix to the 400x400 matrix\n",
        "        new_image = np.hstack([left_zeros, new_small_image])\n",
        "        new_image = np.hstack([new_image, right_zeros])\n",
        "        new_image = np.vstack([new_image, bottom_zeros])\n",
        "        new_image = np.vstack([top_zeros, new_image])\n",
        "        \n",
        "        #adding the new image/label to the dataset that will be returned\n",
        "        synth_data.append(new_image)\n",
        "        synth_labels.append(new_label)\n",
        "        #print(\"Image shape: \", len(new_image), len(new_image[0]), \"Label: \", new_label)\n",
        "    return synth_data,synth_labels\n",
        "\n",
        "  \n",
        "def prep_data_keras(img_data):\n",
        "    \n",
        "    synth_img_height = 224\n",
        "    synth_img_width = 224\n",
        "    \n",
        "    img1 = np.array(img_data, dtype=\"float32\") / 255.0\n",
        "    img2 = np.array(img_data, dtype=\"float32\") / 255.0\n",
        "    img3 = np.array(img_data, dtype=\"float32\") / 255.0\n",
        "    img_data = np.concatenate((img1, img2, img3), axis=2)\n",
        "\n",
        "    img_data = img_data.reshape(len(img_data),synth_img_height,synth_img_width,3)\n",
        "    \n",
        "    return img_data\n",
        "\n",
        "def convert_labels(labels):\n",
        "  targets = np.array(labels, dtype=\"float32\")\n",
        "  return targets\n",
        "\n",
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "print(X_train.shape)\n",
        "\n",
        "X_synth_train,y_synth_train = build_synth_data(X_train,y_train,60)\n",
        "\n",
        "\n",
        "X_synth_test,y_synth_test = build_synth_data(X_test,y_test,10)\n",
        "print(\"build synth data completed\")\n",
        "train_labels = convert_labels(y_synth_train)\n",
        "print(\"convert train labels completed: shapey = \", train_labels.shape)\n",
        "test_labels = convert_labels(y_synth_test)\n",
        "print(\"convert test labels completed: shapey = \", test_labels.shape)\n",
        "\n",
        "train_images = prep_data_keras(X_synth_train)\n",
        "print(\"convert train images completed: shapex = \", train_images.shape)\n",
        "test_images = prep_data_keras(X_synth_test)\n",
        "print(\"convert test images completed: shapex = \", test_images.shape)\n",
        "\n",
        "\n",
        "\n",
        "vgg = tf.keras.applications.VGG16(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=tf.keras.Input(shape=(224, 224, 3)))\n",
        "\n",
        "# freeze all VGG layers so they will *not* be updated during the\n",
        "# training process\n",
        "vgg.trainable = False\n",
        "\n",
        "\n",
        "# flatten the max-pooling output of VGG\n",
        "flatten = vgg.output\n",
        "flatten = tf.keras.layers.Flatten()(flatten)\n",
        "\n",
        "# construct a fully-connected layer header to output the predicted\n",
        "# bounding box coordinates\n",
        "bboxHead = tf.keras.layers.Dense(128, activation=\"relu\")(flatten)\n",
        "#bboxHead = tf.keras.layers.Dense(64, activation=\"relu\")(bboxHead)\n",
        "bboxHead = tf.keras.layers.Dense(32, activation=\"relu\")(bboxHead)\n",
        "bboxHead = tf.keras.layers.Dense(4, activation=\"sigmoid\")(bboxHead)\n",
        "\n",
        "# construct the model we will fine-tune for bounding box regression\n",
        "model = tf.keras.models.Model(inputs=vgg.input, outputs=bboxHead)\n",
        "\n",
        "\n",
        "\n",
        "# train the network for bounding box regression\n",
        "\n",
        "INIT_LR = 1e-4\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=INIT_LR)\n",
        "model.compile(loss=\"mse\", optimizer=opt)\n",
        "print(model.summary())\n",
        "\n",
        "print(\"[INFO] training bounding box regressor...\")\n",
        "H = model.fit(\n",
        "\ttrain_images, train_labels,\n",
        "\tvalidation_data=(test_images, test_labels),\n",
        "\tbatch_size= 32,\n",
        "\tepochs= 25,\n",
        "\tverbose=1)\n",
        "\n",
        "score = model.evaluate(test_images, test_labels, verbose=0)\n",
        "print(score)\n",
        "print(model.metrics_names)\n",
        "\n",
        "model.save(\"H.h5\", save_format=\"h5\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JtMWnPVswYz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14513cbd-fa5a-46a5-e227-0f5b554f2fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "build synth data completed\n",
            "convert train labels completed: shapey =  (60, 4)\n",
            "convert test labels completed: shapey =  (10, 4)\n",
            "convert train images completed: shapex =  (60, 224, 224, 3)\n",
            "convert test images completed: shapex =  (10, 224, 224, 3)\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               3211392   \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 4)                 132       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,930,340\n",
            "Trainable params: 3,215,652\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "None\n",
            "[INFO] training bounding box regressor...\n",
            "Epoch 1/25\n",
            "2/2 [==============================] - 37s 20s/step - loss: nan - val_loss: nan\n",
            "Epoch 2/25\n",
            "2/2 [==============================] - 38s 21s/step - loss: nan - val_loss: nan\n",
            "Epoch 3/25\n",
            "2/2 [==============================] - 36s 19s/step - loss: nan - val_loss: nan\n",
            "Epoch 4/25\n",
            "2/2 [==============================] - 35s 19s/step - loss: nan - val_loss: nan\n",
            "Epoch 5/25\n",
            "2/2 [==============================] - 35s 19s/step - loss: nan - val_loss: nan\n",
            "Epoch 6/25\n",
            "2/2 [==============================] - 35s 19s/step - loss: nan - val_loss: nan\n",
            "Epoch 7/25\n",
            "2/2 [==============================] - 35s 19s/step - loss: nan - val_loss: nan\n",
            "Epoch 8/25\n",
            "2/2 [==============================] - 35s 19s/step - loss: nan - val_loss: nan\n",
            "Epoch 9/25\n",
            "2/2 [==============================] - 35s 19s/step - loss: nan - val_loss: nan\n",
            "Epoch 10/25\n",
            "2/2 [==============================] - 35s 19s/step - loss: nan - val_loss: nan\n",
            "Epoch 11/25\n",
            "2/2 [==============================] - 35s 19s/step - loss: nan - val_loss: nan\n",
            "Epoch 12/25\n",
            "2/2 [==============================] - 35s 19s/step - loss: nan - val_loss: nan\n",
            "Epoch 13/25\n",
            "2/2 [==============================] - 35s 19s/step - loss: nan - val_loss: nan\n",
            "Epoch 14/25\n",
            "2/2 [==============================] - 35s 19s/step - loss: nan - val_loss: nan\n",
            "Epoch 15/25\n",
            "2/2 [==============================] - 35s 19s/step - loss: nan - val_loss: nan\n",
            "Epoch 16/25\n",
            "2/2 [==============================] - 35s 19s/step - loss: nan - val_loss: nan\n",
            "Epoch 17/25\n",
            "2/2 [==============================] - 35s 19s/step - loss: nan - val_loss: nan\n",
            "Epoch 18/25\n",
            "2/2 [==============================] - 35s 19s/step - loss: nan - val_loss: nan\n",
            "Epoch 19/25\n",
            "2/2 [==============================] - 35s 19s/step - loss: nan - val_loss: nan\n",
            "Epoch 20/25\n",
            "2/2 [==============================] - 35s 19s/step - loss: nan - val_loss: nan\n",
            "Epoch 21/25\n",
            "2/2 [==============================] - 35s 19s/step - loss: nan - val_loss: nan\n",
            "Epoch 22/25\n",
            "2/2 [==============================] - 35s 19s/step - loss: nan - val_loss: nan\n",
            "Epoch 23/25\n",
            "2/2 [==============================] - 35s 19s/step - loss: nan - val_loss: nan\n",
            "Epoch 24/25\n",
            "2/2 [==============================] - 35s 19s/step - loss: nan - val_loss: nan\n",
            "Epoch 25/25\n",
            "2/2 [==============================] - 35s 19s/step - loss: nan - val_loss: nan\n",
            "nan\n",
            "['loss']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the model training history\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "N = 25\n",
        "H = load_model('H.h5')\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Bounding Box Regression Loss on Training Set\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc=\"lower left\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "iELAy9rBTMLi",
        "outputId": "b2d918e8-6232-4ad0-c437-bc64300a946f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e5b7eb793f96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'H.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ggplot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'No file or directory found at {filepath_str}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at H.h5"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#concat tester\n",
        "import numpy as np\n",
        "x = np.ones((10,5,5,1))\n",
        "y = np.ones((10,5,5,1))\n",
        "z = np.ones((10,5,5,1))\n",
        "\n",
        "answer = np.concatenate((x,y,z), axis=3)\n",
        "print(answer.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60-u-HmjMp_W",
        "outputId": "4f668e05-871c-49dd-a7cf-227faf31c4d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 5, 5, 3)\n"
          ]
        }
      ]
    }
  ]
}